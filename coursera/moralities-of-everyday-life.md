## Introduction to the Course

My research is, focuses on different areas, including the science of pleasure, of religion and especially morality, and I do scientific experiments that get written up in scientific journals.

But I also am interested in presenting the fruits of this research and the fruits of other people's research to a broad audience. So, I, I publish articles in popular magazines, and I also write books.

Put more generally, this course is about good and evil, and to illustrate in more detail what I'm talking. But I'll giving 3 short examples of the sorts of things we'll be looking at in this course.

Kindiness: altruism or pro-social behavior. As when, with no obvious payoff, we're nice to another individual. I'm primarily a developmental psychologist and a lot of my examples are going to be with children, so I'll give you an example of this with children, and this is from the work of Felix Barnigan and Michael Thomasello.

So they set up an experiment where you have a toddler, and the toddler's sitting in a room, and then somebody needs help. And the question is, without anybody prompting the toddler. What does the toddler do? Toddler opens a cabinet when the adult can't get it opened.

There's kindness, but there's also cruelty. There's evil. There's viciousness. Cat woman thrower: She says, at one point she says, it was a split second of madness. I thought it would be funny. And, it's just a cat. And people were not pleased by these excuses.

They were not pleased by her behavior. And she was attacked by the press. And, the, then she needed police protection, because people wanted to kill her for throwing the cat in the bin.Why would strangers be enraged at what the woman did? They weren't involved. They weren't harmed.

And I think this sort of incident tells us something interesting about morality. Which is that morality matters. When I see something evil being done, even if I'm not involved in it, there's often a punitive impulse. There's an impulse that. The perpetrator should be punished. Justice should be done. And the question of where that comes from, how the system evolved.

How on the one hand do we have a psychology built for empathy and compassion and kindness, as in that child helping the man. And in another way have a psychology built for justice, for punishment, as in the case of the attacks on this woman.

Where does this all come from? And those are questions that occupy us. We'll also be interested, and this is my third example, in human differences. Hundreds of years ago, in the state of Conneticut in which I'm lecturing, people owned slaves. That is people owned other people.

I would imagine very few of you think slavery is right. Very few of you think slavery is moral. But hundreds of years ago people did practice slavery. And many people thought it wasn't wrong. In fact, many people thought that slavery was a moral institution justified by the Bible, justified by history.

What can we say about the psychology of the people back then who thought so differently from how we think? And what can we say about the changes that brought us form then to now? What is the proper explanation for why our views about something like slavery Have changed so radically over history.

Now moral differences aren't just a matter of history. They're not just a matter of then versus now. They're also a matter of clashes between cultures.

One view of things, the view which I actually hold is that the, the, the mass murder of Americans was a horribly immoral act. And the punishment however to punishment or murder of Bin Laden was a just retribution.

But there are many people around the world who see things very differently. They might see that hack on America as a just, reasonable, moral act and the murder of Bin Laden as a cowardly retaliation. The people who orchestrated That hacks 9/11 were not by any standard insane. They were not by any normal standard psychopaths.

Rather, they were driven by a moral vision. Now, again, some moral vision eyes see as grossly mistaken but they see mind as grossly mistaken and at the very minimum then What we need to do as scientists interested in morality is come to grips with the fact that people have such different moral views.

And understand why we have these moral views, where they come from, and possibly how we can deal with these conflicts. Now these are all examples of moral differences between different societies separated by time. Or separated by space. But we could also ask about moral differences within a society.

So in the United States, there's huge differences in how people think about the morality of same sex relationships of gay couples. Again, the point of this course is not trying to commit you to, this view is right or that view or right.

That is just out of the bounds of what we'll be doing here. But we're very interested in, why do some people think this and why do some people think that.

I think this is a question of, both, great intellectual importance, and also great practical importance. And more generally I think, this course will, will talk about specific cases like that, but also deal with foundational issues, that, that I just find incredibly interesting.

So one such foundational issue, is attention between. Moral reasoning. Deliberative conscious thought, decision making thinking things through, the head, and your gut feelings. Your compassion, your emotion, your love, your disgust, your anger, your shame, the heart. And psychologists and philosophers along with theologians and legal scholars and many others Have long tried to address the question of the relative roles of reason and the emotion. In how we le, lead our moral lives and how we come to our moral ideas.

Even more generally than that, we will address the tension between what we en call humanistic views. Our humanistic conception of humanity. Which deals with notions like free will. That sees people as, as agents that can make decisions. That can be blamed, that can be praised, that can be guilty. That, that, that, that can warrant punishment or warrant reward.

A view that might see us as almost as spiritual beings. Not reducible to the physical or, or mechanistic world. Beings with, be beings with souls. Creatures capable not only of wrongness, but also capable of sin. You have that and you have that humanistic view.

And then you have a scientific view. And a scientific view tries to explain our natures in terms of the language of neuroscience, the language of neurons and dendrites, and the limbic system, and the frontal lobe. The language of genes, talks about environmental cues, talks about the effects of parenting, the effects of, of, of one's physical, and social, and emotional environment.

And the question that will occupy us that has occupied me for as, as long as I could remember, is can we reconcile these two views. By our genes and by our environment. Can we say that, and also say that people make choices. And that people should be blamed for their choices or praised for their choices. That people are moral creatures more than anything else on this planet.

Can we reconcile the humanist perspective on us in a scientific perspective? And that's something that we'll be struggling with throughout this course.

So, why would you want to take this course? One reason is the topics are just fascinating. I, Again, I'm, I'm admittedly biased, but who isn't interested in the question of why do some people become violent psychopaths. Who isn't really interested in questions of how are liberals Different from conservatives. How are the fundamentalists different from atheists? How are they better people? Are they worse people? What's the evidence?

A second reason to take the course is that, as we talk about these issues of morality, we will be discussing, and reading, and learning about different domains of both the sciences and the humanities. So a lot of the basis for this work will come from psychology. And we will read and talk about social psychology, developmental psychology, clinical psychology, neuroscience as well as other domains.

The third reason to take the course, and I'm raising this maybe most tenatively. Is that it might make us better people. I am under no illusion that after having read about the studies of morality and read the developmental work and anthropology and neuroscience, that will then be particularly well equipped to say oh now I know that's right and that's wrong. I think understanding them more has nothing but positive benefits.

Why my politics is this and my religion is that And my belief about charity is this. Why I believe these things, I think that understanding where these beliefs and behaviors come from will actually help us in a better way improve on our moral lives.

## 1.1: What is Morality?

The first is there's no definition of morality that people agree on. So the philosopher Stephen Stich points out that philosophers have deep differences over what morality is.

There was a book published in 1970 called Definitions of Morality. And in that book. 13 of the best philosopherss in the world. Philosophers like Elizabeth Anscombe, Peter Strawson and Philippa Foot. Provided their definitions of what morality is. And Stich points out these definitions had very little in common. People had very different views. It doesn't get any different when you look at psychologists.

So the very prominent psychologist, Elliot Turiel, who's done significant work in the psychology of morality, defines morality in a pretty narrow way in terms of justice, rights, and harm. For him, something only counts as immoral if there's a victim, if someone suffers.

In contrast, Jonathan Haidt, whose work we're going to talk about throughout this course. Has a much broader definition of morality. For him, anything that suppresses self-interest and makes cooperation possible is part of morality.

So for Haidt, a religious ritual might be part of our moral psychology, part of our moral life. For Turiel it wouldn't be. So given the sort of disagreement, it would be arbitrary for me to pick out a single definition of morality and go with that.

Also, my view is that beginning with a definition is never a good idea when you're dealing with scientific questions.

Rather what you do is you begin with a rough idea of what you're talking about, and then you're understanding what counts as falling within that domain shifts as a result of your understanding.

I think if we ever get a definition of morality, it means we're kind of finished, the study of it. And we're nowhere near that point now. We're just beginning. Still, in order to study anything, you need a rough idea what you're studying and so I want to begin with, by talking about what counts as a moral violation. What counts as something wrong?

It's related to notions of reward and punishment. Good things are rewarded and bad things are punished and it's related to emotion such as guilt, shame anger and gratitude. the, the person taking the film makes a comment that suggests he is full of moral indignation. He says dickhead. And if you go to the Youtube video, you'll see much worse comments about these people's behavior.

The behavior strikes us in a sort of significant way as wrong. And because it strikes us as wrong, It, it evokes certain emotional responses. Now, this is a simple example of moral violation. Obviously not the worst thing you could imagine, but a sort of simple and direct. But, there are other moral violations that don't quite fit this mould.

So for one thing, you don't have to, make physical contact to somebody, in order to do something wrong. Most of us would believe it's wrong to shout a racist insult at somebody, or threaten to kill them, or spread lies about them. You could harm people in ways that aren't physical.

You could be immoral by negligence. So, if after the filming of this lecture I get together with the gentlemen operating the cameras, we all get roaring drunk. And I get back into my car and start to drive home. Most people say I'm doing something wrong. Not because I have any ill feelings not because I've hurt anybody, but because I'm, I'm foolishly acting in a way which could harm people.

You could be immoral in some cases by not doing anything at all. So if I choose not to feed my dog, then my dog starves to death. That's awful. If I choose not to feed my child, my baby, that's even more awful. That's murder.

Because I have obligations to those individuals that require, that morally require, that I do things. Now there are some cases where What counts as immoral is different from what counts as illegal and these cases are particularly salient with regard to issues of when you should do something.

So I'm thinking particularly of an example. A few years ago, these two guys Jeremy Strohmeyer and David Cash Jr., they go into a casino in Nevada. And Jeremy Strohmeyer sees this little girl. Gets her to come with him into the women's bathroom, and molests and murders her. He is later caught, you know, charged, sentenced.

Plainly what he did was terrible. But I'm more interested here in what his friend did, which is nothing. His friend sort of said, half-heartedly, tried to get Strohmeyer to stop, got bored, and went for a walk. Now it turns out he didn't do anything legally wrong. At the time in Nevada it's not a crime to allow somebody else to do a crime. And in fact, so, so he wasn't charged with anything. And in fact he didn't really feel wrong about what he did. He was later interviewed on the radio. And, and when he was asked his feelings, he said he said this.

The simple fact remains I don't know this little girl. And then he, he said more generally, I don't know people in Panama or Africa who are killed every day, so I can't feel remorse for them. And he went on, why should I feel remorse for this girl? I didn't do anything wrong.

Other people disagreed. And although he was never charged with a crime because he didn't commit the crime, there were protests, there were, there were people. He was a student at University of California at Berkeley, and people protested, demanded that he get thrown out of school. For what he did. And even now, years later, if you look up his name online you'll see there are people stalking him. They don't know him. But they'll stalk him. They want to make sure that, that everybody knows what he did, and that he suffers for what he did.

And this is another, this is a way in which morality can have broad scope. Another sort of example. Is that not all moral violations involve victims. Or least they don't always involve victims in clear and obvious sense. I have here a list of some things. Most of which are illegal in the United States.

> Drug use, voluntary selling of bodily organs, prostitution, homosexuality, bestiality, incest between consenting adult siblings, cannibalism

Homosexuality used to be illegal in the United States. There were sodomy laws that were applied almost exclusively to homosexuals. Now, due to a Supreme Court decision, it's no longer illegal. The rest are still, in various forms, illegal, and they're illegal in other countries as well. 

Now your mileage may vary. Some people will look at this list and say, I don't see anything wrong with all of that. I mean, I don't want to indulge in any of this, but what consenting adults do is fine. It doesn't bother me. Others will see some of these as morally wrong.

And you might see some of these as morally wrong because you believe there really is a victim. You might think that although prostitution involves, on the face of it, consenting adults and so on, Still, the institution of prostitution is coercive and really does make people's lives worse. 

Or, you might think that these are wrong, not so much because they harm somebody but simply because they're wrong. Take consensual cannibalism. Somebody dies, and in their will they say, after I'm dead someone else could eat me. It's all consent, and so on. But some people say that's just not right. I don't care if nobody's harmed. We shouldn't be doing that, to one another.

And this is part of the scope of morality. You, you also get cases where, there isn't apparent harm, and it seems wrong, even when it doesn't rise to the level, of a crime. Suppose I get together with my friends, say fellow Yale professors. Suppose we are sitting in a club, we're sipping sherry, and we're all white males. And we start enga-, telling jokes, and we say, you know, sexist jokes and racist jokes, the most foul jokes you could imagine. But still, we're telling, we're telling the jokes and we leave and we're happier than when we came in.

And nobody hurts and nobody's feelings were hurt. But still, there is the intuition in at least some of us that, that was wrong. You know, you shouldn't be doing that sort of thing. So, the scope of morality is broad. I'm trying to sort of persuade you that what counts as right and wrong has, has broad scope.

Morality is everywhere. A lot of my examples involve sex, and clearly, many, there are certain acts of sex that most everybody find wrong. You, people find it wrong, the idea of sex with a young child. Certainly sex that involves coercion is wrong. People have different attitutes about promiscuity, virginity, heterosexuality, homosexuality bisexuality. Bestiality, masturbation, fetishes. And these differences are profound.

What counts as a, a moral violation for one person could be a point of pride for another. This guy walks into a church. And he goes to a confessional booth. And he immediately says, Father, I'm 70 years old. And I have sex. I have had sex with two 20 year olds. And the priest is kind of stunned. And says, how long has it been since your last confession? And the guy says, I've never been to confession before. I'm not Catholic. And the priest says, so why are you telling me this? And the guy says, I'm telling everybody.

What could be a point of pride to one could be a point of disgust to another. Food. Most people have some moral restrictions on what to eat. For some of us, these moral restrictions are grounded in religion. Other people have more restrictions on what they can eat because of concerns about the suffering of animals. Or worries about damage to the ecosystem.

The most obvious cases of morality, involve family and friends. So, we feel moral obligation towards our family and friends, we, we feel gratitude when people do right by us, betrayed if they don't. The most obvious example is the obligation that a mother or father has towards a child. But these obligations extend. They extend towards siblings. They extend towards people who aren't related but are married, are close friends and so on.

Morality applies to strangers as well. Many of us give to charity and many of us give to charity to help people we don't know and who will never help us back. Even if you don't give this to charity, you believe you have some moral obligations to strangers. You can't kill them, for instance. You can't make them suffer.

Politics is full of morality. Now, I don't want to, I don't want to overstate this. There are some political differences that people have that aren't moral. You may, you and I may share the same goal. We agree on the morality. Now we're sort of struggling with this, with the question of how to do it?

As I'm giving this lecture, the United States is currently in, the United States Congress is currently debating over whether to allow Obama to bomb Syria. Now, there's a lot of practical issues here, but a lot of those questions fundamentally moral? Is it right? To, to, to initiate bombing of another country, an act will for surely kill innocents?

Is it right to do nothing, and then let a dictator who commits acts of chemical warfare to go free, to go unpunished? And people have very different intuitions. And again, some of the intuitions are instrumental.

Instrumental meaning that we agree on the goals, we're just trying to figure how to satisfy them. But some of them are more moral. Honest to God disagreements over what the right thing is to do.

My final example of the scope and importance of morality comes from a lovely and quite weird study done in the 1930s by the American psychologist, Thorndike. Thorndike asked people different questions about different activities.

How much money would I have to pay you to do this activity? Now some, some of the activities. They were all unpleasant. But, they were different kinds of unpleasant. So, some were unpleasant just because they were painful, or degrading, or, or, or awful in some way.

How much would I have to pay you to eat a live earthworm, was one of his questions. Or here's another one. How much would I have to pay you to have one of your front teeth removed with a pair of pliers? No anesthesia. That's one of his questions. He also asks questions about moral violations. How much would he have to pay you to do something bad? And, and it's not physically painful, but they're bad. So, one of his answers was, one of his questions was, how much would I have to pay you to strangle a cat with your bare hands? Here are his answers for those two items.

I've taken his answers, he, he got answers, of course in the 1930s dollars. I've translated them, translated them into the money that you'd have to pay now. For the tooth, its an average of 74,000 dollars. For the cat, it's 164,000 dollars. Over twice as much. And that tells us something. That tells us about the pull that morality has. 

That, that it matters so much that we want to be good people. We donâ€™t want to do this bad thing. That, that we would have to, we would rather have an experience of excruciating pain. So, that's morality as we see it.

> Adam Smith: in treating of the principles of morality, there are two questions to be considered. Wherein does virtue consist? What is the tone of temper and tenor of conduct which constitutes the excellent and praiseworthy character? The character which is the natural object of esteem, honor, and approbation.

He's asking a question. Which we would now says is a philosophical question. A normative question. How should we live? What is it to be a good person? What is it to be a virtuous person?

Or in other words, how and by what means does it come to pass that a mind prefers one tenor of conduct to another? Denominates the one right and the other wrong. Considers the one is the object of approbation on a reward and other of blame center and punishment.

But this is a different question. Now he's not asking what is the good. Now he's asking what's going on in our minds, and our brains. That causes us to say, that's good, and that's bad. That's the right way to live, and that's the wrong way to live.

And throughout this course we're going to deal with both questions. We're mostly interested in a psychological question. We're mostly interested in how people think about morality. What, what governs people's choices? What governs people's intuitions?

## 1.2: Philosophical Approaches

What is it to be good? What distinguishes good from, from evil? Right from wrong? And it turns out there are two very general approaches that most philosophers and most scholars, fall into.

#### Consequentialism

And one is consequentialism. Consequentialist approaches are a dominant way of thinking about morality. Traditional philosophers include David Hume and John Stuart Mill. But most of all, Jeremy Bentham. Who can be taken as the great champion of this approach.

And so for, Bentham argued that when it comes to morality, when it comes to being a good person. Comes to, to being moral. Results matter. They call, that is why they call consequentialism. Consequences matter. And what you should do is, you should always act in a way That's going to promote the best consequences, that's going to make the world better. What it is to do good, is to make the world better. What it is to do bad, is to make the world worse.

For Bentham it reduced to pleasure and pain. So Bentham summarizes his view as follows. He says, nature has placed mankind under the governance of two sovereign masters. Pain and pleasure. It is for them alone to point out what we ought to do. What you're supposed to do is calculate, how many people or how many animals are going to be affected by what you do? Both negatively and positively? How intensely are they affected? And you kind of add everything up for one option, and you add everything up for your other options. And then you choose the action that's going to produce the greatest overall amount of good.
 
So does, to see real examples of this, take some cases with people have argued about through
history and argue about now. Should torture be illegal, always? Or are there ever cases where torture is okay? Bentham thinks torture is justifiable if the tortured person can set of a bomb or something which will hurt more people.

Homosexuality: He said, what's the problem? He said, look if, if people's private acts, being permitted to privately engage in romance and love and sex with someone of the same gender. If that gives pleasure, then it's good. And if it's private, who could it harm?

Now you could talk about the pain that people who are exposed to it, forced to see it, or whatever. But if these are, since these are private acts. It, it, it seems, it seems there's no reason to preclude' em.

And so Bentham was actually very progressive, when it came to matters of sexuality. In part, it's very radical. Because, it's you notice, there's nothing to be said about God here. Or divine rules. There's nothing to be said about abstract moral laws and moral principles. it, it, it gives up what a lot of people think is central to morality.

But it has its problems. And I, I want to be clear about some of its problems. There's no philosophical theory and morality that, that, that seems to work for everybody. They all have subtle problems and complexities.

So, critics of consenquentialism point out that it often forces us to accept as moral, things that intuitively in our gut, just awful. So for a consenquentialist for instance it is perfectly, it is a good thing to torture a child to death.

If by doing so, you raise the happiness level of other people. Because the math works out. Over all, torturing leaves the world a better place than without the torturing. But, that seems wrong. Consequentialists give no special credit to bonds of family and friendship. And in that way as well, their account. It, it's a counter intuitive theory. My son needs an operation. And it's an expensive operation, so I save my money. And, without this operation, he'll go blind. Save's his money my money. And I give him the operation.

And most people would say, yeah, that's a good thing to do. That's what you're supposed to do. But for the consequentialist, that's awful. What I should be doing instead is taking that same money, and giving to the poor people of the world. Because the same money that could save my child's sight, could save the lives of a dozen, a hundred people.

well what about, sending a child to an expensive school? Buying him books, buying him toys, or games, is awful. Because that same money could be used for far greater benefit, for suffering strangers. And those are unintuitive consequences. Now, some consequentialists would say, you know, that really is true.

But many people, including me, find these consequences of consequentialists, so outlandish that it's hard to accept it fully as a moral theory. Then there's another problem. It's that consequentialism might, in some way, miss the point of morality. So, why is rape wrong?

Consequentialists agree that violent rape, that rape is wrong, morally wrong. But here's why they think it's wrong. They think it's wrong because typically in an act of rape, the suffering of the victim. The person who is raped, outweighs the pleasure of the rapist. And so it's wrong. But, if you think about it, that seems absurd. That implies, for instance, that as a rapist gets more and more pleasure, rape would become more and more okay. It implies that if there are multiple rapists who got great pleasure from the act. And the victim, perhaps was unconscious and didn't suffer that much, Then rape would be okay.

And this isn't an outlandish circum, an outlandish conclusion. Because it seems to miss the point. Which is what's wrong about, about a crime like rape or, or, or murder or torture. It's that people have a right not to be harmed. It, it's that, it's, there's a wrongness to assaulting somebody, that transcends the balance of pain and pleasure.

And so, so, it, the critics of consequentialism say that although it maybe, to some extent, a reasonable guide to how to live your life. It fails as a moral theory, because it captures what's most important about morality.

#### Deontology

What they share is the idea that there are moral constraints in some actions, regardless of the consequences. That is there are moral rules that apply. regardless, you know? There are moral rules that apply, even if it turned out an action causes more pleasure than pain, still, some of those actions are just plain wrong.

And of course, the great champion of deontological approaches is the philosopher Immanuel Kant. And Kant expanded at great length, in great subtlety, on morality. And tried to ground his approach to morality on pure reason.

Arguing, let's forget about gut feelings or emotion. We can figure out what the right thing to do just through our intelligence and our rationality.

And the way he did it was, he introduced the idea of the categorical imperative. So a lot of what we do is grounded on our desires. So if you want to see a movie, which is a desire, what you should do is go buy a ticket. If you want to drink some water, go to the sink and pour some water. And those are a hypothetical imperatives for Kant. They are if, then given a desire, do such and so.

But Kant argued there are also categorical imperatives. And categorical imperatives are grounded solely on reason. Any rational being would arrive at a categorical imperative. And so the, in particular, the idea is that any rational being will appreciate that what you should do, is act as if your action would become a universal law.

So when you decide to do, to do this versus do that. You should ask yourself, if everybody did this versus that? How would the world be? Would it demolish our way of living? So, one of Kant's great examples was lying.

If you're a consequentialist, and you're asked, should you lie? The answer is, well, it depends on the consequences. Kant has none of that. Kant says you should never lie. Never. And the reason for that is that, what if everybody lied? Well, if everybody lied, communication would fall apart. Language would fall apart. And our way of living would be destroyed.

But suppose I have Smith. And Smith is in my, in my my living room. And there's a knock on the door. And I open up the door and it's an insane murderer with an axe. And he says, I want to kill Smith. Is Smith in your house? For a consequentialist, you say no. He went that away, and then you call the police. For Kant, you say, yeah, back there. Because you shouldn't lie, regardless of the consequences.

When you fix yourself on a certain deontological theory, your theory will give you clean answers. So many philosophers and many people, actually. Think there's something wrong with torture. There's something wrong with intentionally inflicting pain on another person. And it's a sort of wrong that transcends the consequences.

So even if torturing one person, would save 100 other people. You shouldn't do it. Because it's just not the sort of thing you do. Some people feel, with regard to homosexuality and, and, and other forms of sex. They're just wrong. It doesn't matter whether on the whole they make the world, people happier, or they don't make the world, people happier.

It's not the issue. The issue is, these things are intrinsically wrong. Now, one of the merits, one of the strengths of, deontological approaches. Is that, unlike the consequentialist approach, they really do sort of have the flavor of morality. They, they capture the idea that some things are wrong, intrinsically.

You don't just add up pain and pleasure. But there are several problems with these deotological approaches. So one problem is these, these categorical rules that, that people like Kant propose. Often seem crazy. The one about never lying under any circumstances, seems insane. Why couldn't the principle be you shouldn't lie unless by lying, you save somebody's life.

And this sort of objection, this category of objection, speaks to a more general problem. Which is, where do all these moral rules come from? So someone like Kant would insist, they come from pure reason. They come from pure rationality.

But, it turns out that when you look at them. The critics of Kant, and the critics of deotological philosophers say, you know, these aren't grounded in rationality. These are actually grounded in your own prejudices and biases and, and, and emotions. So, for instance, Kant thought homosexuality was wrong. Kant also thought masturbation was wrong. And, you know, he's not a consequentialist. He doesn't care how much pleasure is involved in these things. What he said of both of these is, they're violations of ones duty to ones self, not to succumb to animal desires.

And he found that convincing. But many people don't find it convincing. And it's not clear that there is a way to convince somebody who doesn't think that, that these things are wrong, that they are. And so, so the consequentialist starts with an intuitive place. The goodness of pleasure and the badness of pain. The deontological philosopher, struggles a little bit more trying to find a way to ground these abstract rules. 

## 1.3: Reason vs. Emotions

At the idea of framing the psychological question in terms of they philosophical question. So, one way to think about people is that we're, sort of, common sense moral philosophers. We, we think about morality.  We have a, a unconscience, perhaps, an unconscience theory of what's right and wrong.

And then the question is, what kind of moral philosophers are we? One way to explore this, and this has launched dozens, hundreds of experiments, is in terms of a famous thought experiment.

Most people think it's okay to throw the switch for the switch case. Most people think that, that maybe, you know, it's not 100% you throw the switch it's the right thing to do. You save five and one die. But most people think it's wrong to push the man. Most people think you shouldn't do that. So, what does this tell us?

Well, the people that do this research will, will tell you that, one thing it suggests is that we're not consequentialists. because notice these cases are, kind of similar. One theory is that we have in our brains unconsciously usually, a rather subtle philosophical principle and this principle is sometimes called the Doctrine of Double Effect.

And the Doctrine of Double Effect says there's a distinction between doing something bad, like killing or harming somebody as an unintended consequence of causing greater good to happen, and that could be the right thing to do, versus doing something bad, like killing or harming somebody in order to bring about a greater good, and that you shouldn't do. The consequences are identical. But the difference is that in one case, the bad thing is a regrettable byproduct. I'm sorry, in the good case, the bad thing is a regrettable byproduct.

Well, in the bad case, it's an instrument through which you act. So, this often comes up, in case, cases of just war. Or, or, or in philosophical debates and political debates over, over what's permissible in war time.

And people who talk about a Doctrine of Double Effects say, consider two examples. In one example there's a munition's factory. If you bomb it, there's good reason to believe it would, defeat the enemy and the war would come to an end and millions of lives would be saved. But if you bomb it, there's people who work in the factory who are innocent, and they will die. Should you bomb it?

Well, that's a hard question. But many people would argue if the benefit is great enough, having some innocent people die as a byproduct is permissible. Now compare to another case, there innocent people and if you blow them up, if you kill them, that will terrorize the enemy population. They'll know you're serious and then the war will end, saving millions of lives and so on. In fact, you can make these case so that they have identical consequences so that the same number of people die in the same way.

And the Doctrine of Double Effect says, the difference is, in the case where you may do it, the innocents are collateral damage, but you don't want them to die. They're just a regrettable byproduct. But here, you're killing people in order to bring about an effect and you shouldn't do that.

And the connection to trolley problem, is pretty clear. This, this could explain, some people
believe, why we think so differently about these two cases. In the switch case, one person dies but their death is an accident and their death does nothing. If they were to leave the track, you'd be happy.

They don't have to die and it's wonderful. In the bridge case, the person's death is necessary. If they were to leave the bridge, it doesn't work any more, the five will die. You need them.

So, this way of looking at things where we take these abstract philosophical theories, we use the philosophical examples, we test people on them, and then we try to explain people's intuitions based on, on these philosophical approaches, is one way to do moral psychhology.

And in fact, I think its fair to say that in the last decade or so there's been a backlash. And in this backlash people have said this is entirely the wrong way to study moral psychology. We should not think of people as, as these philosophical creatures doing these abstract rules, rather moral, morality is driven to a large extent by gut feelings.

Think of what happens when you put a new food into your mouth. You don't have to decide if it's disgusting. You just know. You don't have to decide if a landscape is beautiful. You just know.

Moral judgments are like that. They are rapid intuitive decisions and involve the emotional-processing parts of the brain. Most of us make snap moral judgments about what feels fair or not or what feels good or not. We start doing this when we are babies, before we have language, and even as adults, we don't, we often can't explain to ourselves why something feels wrong.  A lot of our morality is driven by our gut.

The idea is that if we think reason is important, we are mistaking the tail for the dog. It's, it's the motion that counts. Haidt writes, moral judge, reasoning does
not cause moral judgment; rather moral reasoning is usually a post hoc construction generated after a judgment has been reached.

David Hume talking about moral reasoning says, look, our moral decisions, our moral understanding is not driven by reason. Rather, he says, reason is, and ought only to be, the slave of the passions.

## 1.4: The Case of Disgust

Disgust is a human universal. It shows up in every culture.  When you're disgusted by something, you don't want to touch it. You, you, you don't want to smell it, and you certainly don't want to eat it. You don't want it in your mouth.

In the extreme, something sufficiently disgusting could make you vomit, and it will, always illicit this distinctive emotion, this distinctive feeling, that we identify, as disgust.

Evolutionary psychologists, interested in emotions, have argued that this feeling evolved for a certain function. It evolved to motivate us, to avoid parasites and poisons. So you think of the things that we are disgusted by, and they share certain things in common. They could poison us, they, they have infectious properties.

But, one of the most troubling facts about disgust, is that people can be disgusting. And this was something pointed out by Charles Darwin, who was always a wonderful and acute observer of of human interaction. Whilst I felt utter disgust at my food being touched by a naked savage, though his hands did not appear dirty.

People are disgusting. Our response to strangers, our response to being touched by strangers, to, to smelling strangers and so on, is often a response of disgust. Now, there's some debate in the field as to, why people illicit disgust.

Some scholars say, people illicit disgust because people carry diseases. Strange people will carry strange diseases.

Others argue that it's not really that, rather, people are disgusting because we are fleshy things. We are made of meat. We, we, we produce feces, and urine, and other things. We, we are, we are animal like things and if you think of people in that way, you can be readily disgusted by them.

Once you are disgusted by them, it can have moral effects, it could have consequences and the consequences of being disgusted by somebody, of being disgusted by a group of people, are profoundly negative.

Every genocidal movement that, that has left a record, exhibits signs that disgust was used, to illicit hatred towards the despised group. Most movements involving prejudice and discrimination, don't just say those people, they're rotten, they're stupid, they're mean. They also say, they're disgusting.

This is an insight that the philosopher Martha Nessbaum, nicely summarizes. Throughout history, certain disgust properties, sliminess, bad smell, stickiness, decay, foulness, have repeatedly and monotonously been associated with Jews, women, homosexuals, untouchables, lower class people.

All of those are imagined as tainted, by the dirt of the body. and, and this is an example from Nazi propaganda. But there are, are countless such examples, where a despised group is described as, disgusting. There seems to be a natural connection to being disgusted by somebody and, not caring about them.

In fact, wanting them to suffer. Psychologists have studied disgust in the lab. And there's different ways to do it. So, one way to do it is, you can see how easily disgusted people are, and then see how much their disgust sensitivity, predicts other properties about them.

And it turns out that, that your disgust sensitivity is related to certain interesting facts about you. Women, on average, are more disgust sensitive, than men. There's evidence that women become particularly disgust sensitive, at a certain vulnerable point in pregnancy.

Political conservatives, tend to be more disgust sensitive, than political liberals. And most important for what we're talking about here, your disgust sensitivity corresponds to, certain moral attitudes. So for instance, in some, some research finds, that people who are very disgust sensitive, are more likely to be, express negative moral attitudes about homosexuals.

Turns out, being grossed out by this fart spray, doesn't influence your feelings about tax policy. And it doesn't influence your feelings about the environment or, or other things. But it does affect, how you think about groups like homosexuals.

It makes you harsher towards them. It also makes you harsher towards moral violations, you could called purity violations. Like consensual incest or or masturbation in an inappropriate place or stuff like that. If you're disgusted, you're more disapproving.

And these studies suggest that, your feelings about somebody or, or what somebody does, can be influenced by your emotional state. In particular, your emotional state of disgust. Now disgust can also influence certain specific moral judgments. So, so far I've been talking more or less about, moral feelings towards somebody. But what about judgments about, what's right and wrong?

Well, Jonathan Haidt thought up some very interesting examples. And he uses these examples to show that, even people who think, that they're very liberal and quite consequential, can be influenced in their judgments of morality, by whether or not, something disgusts them.

Examples

-  Julie and Mark are our sister and brother. They're adults, they travel together. They decide to have sex with one another. Now, they're very cognizant of worries of having pregnancy and so on, so they use tons of birth control. There's no chance, that, that, that she'll get pregnant. And they have sex and it's great. And they do it several times, and they just love it. And then they decide, they're not going to tell anybody, and and they're not going to do it again. Did Julie and Mark do something wrong?
- Family dog runs out in the street, gets hit by a car. Family brings the dog in, very sad. But then they realize, they have nothing planned for supper tonight. So they cook the dog and eat it. And it's delicious, and they're very happy.
-  The toilet is very dirty but this guy has run out of cleaning supplies, and wants to clean the toilet. Fortunately, he has an American flag. Takes the flag and uses it,
to scrub the toiler clean. Now he's happy, clean toilet. Has he done anything wrong?
-  The chicken case is, this guy goes to supermarket, he buys a chicken, he brings the chicken back home. It's not a live chicken, like a chicken, like you, from the supermarket, he makes love to the chicken, has sex with the chicken. And then he cooks it and eats it. Has he done something wrong?

I'm not asking you, whether he's done something which grosses you out. I, I imagine, you have an answer to that. Has he done anything wrong?

Now, what Haidt finds is, for these sorts of examples, he finds a couple of things. First thing is that, most people, almost everybody find so many things wrong, they find them morally wrong. The exceptions are liberal, highly liberal students from elite universities.

Some of them say no, those are all okay, no one's harmed. But most people, almost everybody, find them wrong. But he also finds, that people are, not usually able to explain, what they find, wrong about them. And he calls this, moral dumbfounding.

Incest: No chance to get pregnant. Other people will not find out. People struggle to find an explanation why they think it is wrong.  Rather, their reaction is because these things disgust them. And because they're disgusting, they're found to be immoral. And if he's right, this would be a case where, our emotions and not our reason, are driving moral judgment.

## 1.5: Cute and Sexy

Our gut feelings can be positive towards somebody. Babies: Very easy to feel fondly towards, that will elicit a desire to protect. It's because it's adorable, because, because of the big eyes and the round cheeks and these sort of cues that we've been wired up to respond to.

And, and, and our, the effects of these cues and how we feel towards people and how we feel towards creatures has, has real effects. Here are two animals. Now, I actually don't have a strong opinion as to which animal is smarter, which animal has a richer emotional life. Which animal feels more pain.

But, what's not a hard question is I know which animal people care about more. One animal we bring into our houses, and we we, we give treats to, and we hold birthday parties for, and we love. And, the other kind of animal we eat. And this does not have to do with the features of the animal.

It has to do with, with how they look. Kittens are cute. Pigs are not. There are other distinctions one could make, more subtle distinctions one could make, concerning sort of positive responses.

And their effects on moral reasoning. So, one research program I've been interested in is, concerns the effects of looking at people's bodies, and to what extent does looking at people's bodies affect how you judge them and think about them morally.

It turns out that when you see somebody's body, it has two effects on your reasoning about them. One is, you actually, in some way, care more about them. You think that they're more vulnerable to pain. You think they're more sensitive to, to, to, to being hurt. You worry a little bit more about them. But you also tend to deny them moral agency.

What I mean by this is that, for most of us, when you look at somebody, you say, well, there's a person that could be blamed, they could be praised, they're responsible for their own actions, they make their own decisions. But when you see somebody's body, that tendency to think of them as an agent goes down a bit. 

Now this, these pictures, the difference I'm showing you here is fairly subtle. And we thought in our experiments we'd be stuck with those sort of subtle distinctions until we found this wonderful book (30 Porn Star Portraits). And this book has photographs, side by side, of the very same men and women. But, in one picture, they're fully dressed. And in the other pictures, they're entirely naked.

We found that when people are naked, you tend, in some way, to be more concerned about them. But also, you tend to deny them moral agency. It really matters. There's something, there's some real psychological truth to the claim made by feminist scholars, that the objectification of women, thinking of women as sexual beings, as physical beings, has an effect, perhaps a pernicious effect on how you think about them and what we find in this work is, it applies to men as well as women.

If you did, you should put these two books together on your shelves separately and then people will look at them and they will wonder what kind of person you are. So, why do naked people, why do bodies, have this sort of effect on us?

One explanation is, that, they inspire lust. And lust somehow blocks certain morals. Sentiment makes you think about a person a different way. Another possibility, that is sort of separate from lust, is that if you see somebody without clothes. They're more like an animal, they lose their dignity. They lose their status. And it's that which is driving the effect.

And we actually, in our research, we don't know the answer to that. But we do know, from other work, that the feeling of lust, the feeling of sexual arousal can have an affect on your moral decision making.

Dan Ariely experiment (the masturbating thing): So you could ask people whether or not they could imagine being attracted to a 12-year-old girl. And it turns out if people were non-aroused, like, you know, a quarter say yeah. But when they're aroused, it doubles. Or or becoming sexually excited, by an animal.

The most disturbing findings involved a sort of date rapey, questions. Would you slip a woman a drug to increase the chances that she would have sex with you? When men were not aroused, 5% said yes. But this number got much, much bigger when they were aroused.

I, it tells people, that your psychology changes when you're aroused. You're no longer the same person in an important sense. Your sense of what turns you on when you're aroused is different from when you're not aroused. And it's yet another argument that our morality can be influenced by not just by reason, but by the emotions.

## 1.6: Returning to the Trolley

We said this might be because people have this abstract philosophical principle that sees, sort of, a subtle difference between these two, and for instance, the principle we talked about was, in the switch case, the guy dying is an accident, doesn't do any good.

In the bridge case the guy dying is essential. He's an instrument through which to bring about the good. And this was the analysis we had. But there's an alternative. This alternative was proposed by Joshua Green and has a lot of support. The alternative says, that's not what's happening at all.

And what he did was, he had people solve trolley problems, like reasonsabout moral problems, while they were hooked up to an fMRI. He found that the switch case activated parts of the brain in the frontal cortex, the part of the brain that's up front here. And these are parts of the brain that are typically involved concious deliberative reasoning. And these parts of the brains would be active and people would make their choice. And often their choice would be, yeah they should throw the switch, that makes sense. Five lives matter more than one life.

What about, the bridge case? Well here the same part of the brain, was active. Presumably doing the calculations of, five versus one. But also, various other parts of the brain that are involved in conflict and emotion, emotional feelings, light up stronger. And, for these sorts of cases, people say that you shouldn't push the man.

The way Green analyzes this is, it's not that there's some sort of subtle philosophical principle that governs the difference between the switch case and the bridge case. Rather, 

there's sort of two aspects of our moral psychology. There's controlled rational processes. And the controlled rational processes are, under Green's view, largely utilitarian. They just calculate consequences in a very cold-blooded way. But there's also automatic, involuntary, gut feelings.

And so what Green says is, for the switch case you just map. You, and so you have choosing you have one life and five lives to control process, chug away. And you typically say well, you know, better to save five. Even at the expense of one. But for the bridge case, emotions light up. It's not just a cold blooded calculation one and five, but also this gut feeling. And the gut feeling lights up for green. Not because of any principle or structure. It's, it's the idea that this visceral feeling of putting your hands on somebody and shoving, causes emotional response. That's what's driving it.

It has nothing to do with the doctrine of double effect, or anything like that. It's an emotional response to the physicality of pushing somebody to his death.

We also know from other research that people can be influenced in their choices on the switch case and a bridge case by fiddling with their emotions in various ways. So my favorite example of this is, how do you make people more likely to say it's okay to push the man off the bridge? 

Show them something funny.

So they, so, the researchers found some very funny clips from Saturday Night Live, they showed em to people, people laughed, and then they asked bridge case. And they said, now people said, yeah, I'll push em. Suggesting that there, that, that there aren't these abstract emotion, sorry, the abstract rational principles guiding our choices here, but rather, gut feelings played more of a role.

## 1.7: The Big Questions

Is Hume right? Is, is, is really more reasoning just a slave of the passions? What's the proper relationship between emotion and reason in everyday moral life? Is everything emotional? Does reason play any important role?

Emotion plainly affects our morality. But I want to try also persuade you that reason, cold blooded rational deliberation, thinking things through also affects our moral lives.

Second big question is where do morals come from? So, how much of our moral judgments we've
been talking about, are intuitions about trolley problems and murder and rape and, and masturbation and selling your body organs and eating dogs and so on?

How much of this is explained by evolution, so part of our brain structured by our, our evolutionary history, how much of it is explained by personal, individual experience, how much varies from culture to culture, and how much of it is just personal choice?

And then the third question, the big question maybe, is can scientific inquiry - including psychological inquiry - help us with morality? Can it help us be better people?

Some people say it is a fallacy to go from the way the world is, which is what science studies, to the way the world ought to be, which is the proper domain of ethics. But things might be more complicated than that, and we're going to struggle with these questions, throughout.

And for the reading, for the assignments for this week you're supposed to watch their TED talks where they present their view in detail. What I want to do here is, as a way to introduce it, present a snippet from each of their talks.

And what I like about, about this is they're each articulate proponents of a perspective on morality, but the perspectives are quite different. They are, they are, are as close to opposites as you could find. 

Sam Harris argues there's object the facts about the moral landscape. And it, what makes it a moral landscape is, the space has hills where, where things are good, and valleys where things are bad. And there are objective facts. And he argues that many popular moral (mostly religious) views - are just wrong. They're as wrong about morality as they are about, you know, cosmology.

>> When talking about morality, we value differences of opinion in a way that we don't in any other area of our lives. The Dalai Lama thinks that helping other human beings is an integral component of human happiness. Ted Bundy was very fond of abducting and raping and torturing and killing young So we appear to have a genuine difference
of opinion about how to profitably use
one's time.

>> Most western intellectuals look at this situation and say, well there's nothing for the Dalai Lama to be really right about, really right about. Or for Ted Bundy to be really wrong about. That admits of a, of a real argument. That, that, that, that potentially falls within the purview of science.

> Well, you know, that he's like chocolate, he likes vanilla there's, there's no, there's nothing that one should be able to say to the other, that should persuade the other.

> Now notice that we don't do this in science. Whenever we are talking about facts, certain opinions must be excluded. Then, that is what it is to have a domain of expertise. That is what it is for knowledge to count. 

> How have we convinced ourselves that in the moral sphere, there is no such thing as moral expertise? Or moral talent? Or moral genius, even? How have we convinced ourselves that every opinion has to count? How have we convinced ourselves that, that every culture has a point of view on these subjects worth considering? Does, does the Taliban have a point of view on physics that is worth considering? No.

> How, how is there ignorance, how is their ignorance, how is their ignorance any less obvious on the subject of human well being?

> So, so this I, I think is what the world needs now. It needs people like ourselves to admit that there are right and wrong answers to questions of human flourishing. And morality relates to that domain of facts. It is possible, for individuals, and even for whole cultures to care about the wrong things. Just admitting this, will transform our discourse about morality.

> We live in a world in which, the boundaries between nations mean less and less, and they will one day mean nothing. We live in a world filled with destructive technology, and this technology cannot be uninvented. It, it will always be easier to break things than to fix them.

> It seems to me, therefore, patently obvious that we can no more, respect and tolerate vast differences in, in notions of human well being than we can respect or tolerate vast difference in the notions about how disease spreads. Or in the, in the safety standards of buildings and airplanes. We simply must converge on the answers we give to the most important questions in human life.

> And to do that, we have to admit that these questions have answers. Thank you very much.

So Jonathan Haidt in contrast has a very different perspective. Haidt emphasizes a respect for pluralism. In particular, he argues that many moral frameworks including common ones that are grounded in religion, deserve respect.

> You have the markings of, of Vishnu on the left, so we could think of Vishnu as the
conservative god. You have the markings of Shiva, on the right. Shiva is the liberal god, and they work together.

> You find the same thing in Buddhism. These two stanzas contain I think the deepest insights that have ever been attained, into moral psychology.

> "From the Zen master Seng-ts'an. If you want the trust to stand clear before you, never be for or against. The struggle between for and against is the mind's worst disease."

> Well, if you take the greatest insights from ancient Asian philosophies and religions and you combine them with the latest research on moral psychology, I think you'd come to these conclusions. That our righteous minds were designed by evolution to unite us into teams, to divide us against other teams, and then to blind us to the truth.

> So, what should you do? Am I telling you to not strive? Am I telling you to embrace Seng-ts'an and stop?  No, absolutely not. I'm not saying that. This is an amazing group of people, who are doing so much, using so much of their talent, their brilliance, their energy, their money to make the world a better place, to fight, to fight wrongs to, to solve problems. But as you can't just go charging in, saying you're wrong and I'm right. because as we just heard, everybody thinks they are right.

> A lot of the problems we have to solve are problems that require to change other people. And if you want to change other people, the much better way to do it is to first understand who we are. Understand our moral psychology, understand that we all think we're right, and then step out. Step out of the moral matrix, just try to see it as, as a struggle playing out in which everybody does think they're right. And everybody at least has some reasons, even if you disagree with them, everybody has some reasons for what they're doing.

But what again, what I hope to do is, as we talk more and more about the science of morality, talk more about theories, talk more about data. We'll be in a better position, all of us, to better decide, what's the right answer to these big and these very important questions.

## Readings 1.1: The Moral Instinct, Steven Pinker

For most people, Mother Theresea > Bill Gates > Norman Borlaug for who is most admirable. But Borlaug used the agriculture revolution and is credited with saving a billion lives, Gates fights against malaria and diarrhea, and Mother Teresa's patrons were offered prayer but harsh conditions and primitive medical care.

Our heads can be turned by an aura of sanctity, distracting us from a more objective recokning of the actions that make people suffer or flourish.

#### The Moralization Switch

Moralization is a psychological state that can be turned on and off like a switch, and when it is on, a distinctive mind-set commandeers our thinking. This is the mind-set that makes us deem actions immoral (â€œkilling is wrongâ€), rather than merely disagreeable (â€œI hate brussels sproutsâ€), unfashionable (â€œbell-bottoms are outâ€) or imprudent (â€œdonâ€™t scratch mosquito bitesâ€).

The rules it invokes are felt to be universal. Prohibiting rape/murder is universal, while hating brussel sprouts is not.

People feel that those who commit immoral acts desever to be punished. "They can't get away with it." "The infliction of cruelty with a good conscience is a delight to moralists â€” that is why they invented hell." - Bertrand Russell

Moral vegetarians are more likely to treat meat as a contaminant as opposed to health vegetarians. They are more likely to think that other people ought to be vegetarians, more likely to imbue their dietary habits with other virtues, like believing that meat avoidance makes people less aggressive and bestial.

Much of our recent social history, including the culture wars between liberals and conservatives, consists of the moralization or amoralization of particular kinds of behavior. Even when people agree that an outcome is desirable, they may disagree on whether it should be treated as a matter of preference and prudence or as a matter of sin and virtue. When secondhand smoke was discovered, smoking is now treated as immoral: images of people smoking are censored and entities touched by smoke are felt to be contaminated.

At the same time, many behaviors have been amoralized: divorce, illegitimacy, being a working mother, marijuana use and homosexuality. Many afflictions have been reassigned from payback for bad choices to unlucky misfortunes. There used to be people called â€œbumsâ€ and â€œtrampsâ€; today they are â€œhomeless.â€ Drug addiction is a â€œdiseaseâ€; syphilis was rebranded from the price of wanton behavior to a â€œsexually transmitted diseaseâ€ and more recently a â€œsexually transmitted infection.â€

This wave of amoralization has led the cultural right to lament that morality itself is under assault, as we see in the group that anointed itself the Moral Majority. In fact there seems to be a Law of Conservation of Moralization, so that as old behaviors are taken out of the moralized column, new ones are added to it. Dozens of things that past generations treated as practical matters are now ethical battlegrounds, including disposable diapers, I.Q. tests, poultry farms, Barbie dolls and research on breast cancer. Food alone has become a minefield, with critics sermonizing about the size of sodas, the chemistry of fat, the freedom of chickens, the price of coffee beans, the species of fish and now the distance the food has traveled from farm to plate.

Many of these moralizations, like the assault on smoking, may be understood as practical tactics to reduce some recently identified harm. But whether an activity flips our mental switches to the â€œmoralâ€ setting isnâ€™t just a matter of how much harm it does. We donâ€™t show contempt to the man who fails to change the batteries in his smoke alarms or takes his family on a driving vacation, both of which multiply the risk they will die in an accident. Driving a gas-guzzling Hummer is reprehensible, but driving a gas-guzzling old Volvo is not; eating a Big Mac is unconscionable, but not imported cheese or crÃ¨me brÃ»lÃ©e. The reason for these double standards is obvious: people tend to align their moralization with their own lifestyles.

#### A Universal Morality?

The stirrings of morality emerge early in childhood. Toddlers spontaneously offer toys and help to others and try to comfort people they see in distress. And according to the psychologists Elliot Turiel and Judith Smetana, preschoolers have an inkling of the difference between societal conventions and moral principles. Four-year-olds say that it is not O.K. to wear pajamas to school (a convention) and also not O.K. to hit a little girl for no reason (a moral principle). But when asked whether these actions would be O.K. if the teacher allowed them, most of the children said that wearing pajamas would now be fine but that hitting a little girl would still not be.

Though no one has identified genes for morality, there is circumstantial evidence they exist. The character traits called â€œconscientiousnessâ€ and â€œagreeablenessâ€ are far more correlated in identical twins separated at birth (who share their genes but not their environment) than in adoptive siblings raised together (who share their environment but not their genes). People given diagnoses of â€œantisocial personality disorderâ€ or â€œpsychopathyâ€ show signs of morality blindness from the time they are children. They bully younger children, torture animals, habitually lie and seem incapable of empathy or remorse, often despite normal family backgrounds. Some of these children grow up into the monsters who bilk elderly people out of their savings, rape a succession of women or shoot convenience-store clerks lying on the floor during a robbery.

Though psychopathy probably comes from a genetic predisposition, a milder version can be caused by damage to frontal regions of the brain (including the areas that inhibit intact people from throwing the hypothetical fat man off the bridge). The neuroscientists Hanna and Antonio Damasio and their colleagues found that some children who sustain severe injuries to their frontal lobes can grow up into callous and irresponsible adults, despite normal intelligence. They lie, steal, ignore punishment, endanger their own children and canâ€™t think through even the simplest moral dilemmas, like what two people should do if they disagreed on which TV channel to watch or whether a man ought to steal a drug to save his dying wife.

#### The Varieties of Moral Experience

The exact number of themes depends on whether youâ€™re a lumper or a splitter, but Haidt counts five â€” harm, fairness, community (or group loyalty), authority and purity â€” and suggests that they are the primary colors of our moral sense. Not only do they keep reappearing in cross-cultural surveys, but each one tugs on the moral intuitions of people in our own culture. Haidt asks us to consider how much money someone would have to pay us to do hypothetical acts like the following:

Stick a pin into your palm.

Stick a pin into the palm of a child you donâ€™t know. (Harm.)

Accept a wide-screen TV from a friend who received it at no charge because of a computer error.

Accept a wide-screen TV from a friend who received it from a thief who had stolen it from a wealthy family. (Fairness.)

Say something bad about your nation (which you donâ€™t believe) on a talk-radio show in your nation.

Say something bad about your nation (which you donâ€™t believe) on a talk-radio show in a foreign nation. (Community.)

Slap a friend in the face, with his permission, as part of a comedy skit.

Slap your minister in the face, with his permission, as part of a comedy skit. (Authority.)

Attend a performance-art piece in which the actors act like idiots for 30 minutes, including flubbing simple problems and falling down on stage.

Attend a performance-art piece in which the actors act like animals for 30 minutes, including crawling around naked and urinating on stage. (Purity.)

In each pair, the second action feels far more repugnant. Most of the moral illusions we have visited come from an unwarranted intrusion of one of the moral spheres into our judgments. A violation of community led people to frown on using an old flag to clean a bathroom. Violations of purity repelled the people who judged the morality of consensual incest and prevented the moral vegetarians and nonsmokers from tolerating the slightest trace of a vile contaminant. At the other end of the scale, displays of extreme purity lead people to venerate religious leaders who dress in white and affect an aura of chastity and asceticism.

#### The Genealogy of Morals

The five spheres are good candidates for a periodic table of the moral sense not only because they are ubiquitous but also because they appear to have deep evolutionary roots. The impulse to avoid harm, which gives trolley ponderers the willies when they consider throwing a man off a bridge, can also be found in rhesus monkeys, who go hungry rather than pull a chain that delivers food to them and a shock to another monkey. Respect for authority is clearly related to the pecking orders of dominance and appeasement that are widespread in the animal kingdom. The purity-defilement contrast taps the emotion of disgust that is triggered by potential disease vectors like bodily effluvia, decaying flesh and unconventional forms of meat, and by risky sexual practices like incest.

The other two moralized spheres match up with the classic examples of how altruism can evolve that were worked out by sociobiologists in the 1960s and 1970s and made famous by Richard Dawkins in his book â€œThe Selfish Gene.â€ Fairness is very close to what scientists call reciprocal altruism, where a willingness to be nice to others can evolve as long as the favor helps the recipient more than it costs the giver and the recipient returns the favor when fortunes reverse. The analysis makes it sound as if reciprocal altruism comes out of a robotlike calculation, but in fact Robert Trivers, the biologist who devised the theory, argued that it is implemented in the brain as a suite of moral emotions. Sympathy prompts a person to offer the first favor, particularly to someone in need for whom it would go the furthest. Anger protects a person against cheaters who accept a favor without reciprocating, by impelling him to punish the ingrate or sever the relationship. Gratitude impels a beneficiary to reward those who helped him in the past. Guilt prompts a cheater in danger of being found out to repair the relationship by redressing the misdeed and advertising that he will behave better in the future (consistent with Menckenâ€™s definition of conscience as â€œthe inner voice which warns us that someone might be lookingâ€). Many experiments on who helps whom, who likes whom, who punishes whom and who feels guilty about what have confirmed these predictions.

Community, the very different emotion that prompts people to share and sacrifice without an expectation of payback, may be rooted in nepotistic altruism, the empathy and solidarity we feel toward our relatives (and which evolved because any gene that pushed an organism to aid a relative would have helped copies of itself sitting inside that relative). In humans, of course, communal feelings can be lavished on nonrelatives as well. Sometimes it pays people (in an evolutionary sense) to love their companions because their interests are yoked, like spouses with common children, in-laws with common relatives, friends with common tastes or allies with common enemies. And sometimes it doesnâ€™t pay them at all, but their kinship-detectors have been tricked into treating their groupmates as if they were relatives by tactics like kinship metaphors (blood brothers, fraternities, the fatherland), origin myths, communal meals and other bonding rituals.

#### Juggling the Spheres

America - harm and fairness. Japan - community (fear of nonconfromity). Hindus/Jews - purity (dietary restrictions). Muslims - authority (insulting the prophet.) West hates nepotism/cronyism, but in other parts of the world, family is more important than strangers.

#### Is Nothing Sacred?

And â€œmorally corrosiveâ€ is exactly the term that some critics would apply to the new science of the moral sense. The attempt to dissect our moral intuitions can look like an attempt to debunk them. In reality, none of these fears are warranted, and itâ€™s important to see why not. 

â€œSelfishâ€ genes are perfectly compatible with selfless organisms, because a geneâ€™s metaphorical goal of selfishly replicating itself can be implemented by wiring up the brain of the organism to do unselfish things, like being nice to relatives or doing good deeds for needy strangers.

Nor does reciprocal altruism â€” the evolutionary rationale behind fairness â€” imply that people do good deeds in the cynical expectation of repayment down the line.

In his classic 1971 article, Trivers, the biologist, showed how natural selection could push in the direction of true selflessness. The emergence of tit-for-tat reciprocity, which lets organisms trade favors without being cheated, is just a first step. A favor-giver not only has to avoid blatant cheaters (those who would accept a favor but not return it) but also prefer generous reciprocators (those who return the biggest favor they can afford) over stingy ones (those who return the smallest favor they can get away with). Since itâ€™s good to be chosen as a recipient of favors, a competition arises to be the most generous partner around. More accurately, a competition arises to appear to be the most generous partner around, since the favor-giver canâ€™t literally read minds or see into the future. A reputation for fairness and generosity becomes an asset.

Now this just sets up a competition for potential beneficiaries to inflate their reputations without making the sacrifices to back them up. But it also pressures the favor-giver to develop ever-more-sensitive radar to distinguish the genuinely generous partners from the hypocrites. This arms race will eventually reach a logical conclusion. The most effective way to seem generous and fair, under harsh scrutiny, is to be generous and fair. In the long run, then, reputation can be secured only by commitment. At least some agents evolve to be genuinely high-minded and self-sacrificing â€” they are moral not because of what it brings them but because thatâ€™s the kind of people they are.

Of course, a theory that predicted that everyone always sacrificed themselves for anotherâ€™s good would be as preposterous as a theory that predicted that no one ever did. Alongside the niches for saints there are niches for more grudging reciprocators, who attract fewer and poorer partners but donâ€™t make the sacrifices necessary for a sterling reputation. And both may coexist with outright cheaters, who exploit the unwary in one-shot encounters. An ecosystem of niches, each with a distinct strategy, can evolve when the payoff of each strategy depends on how many players are playing the other strategies. The human social environment does have its share of generous, grudging and crooked characters, and the genetic variation in personality seems to bear the fingerprints of this evolutionary process.

#### Is Morality a Figment?

So a biological understanding of the moral sense does not entail that people are calculating maximizers of their genes or self-interest. But where does it leave the concept of morality itself?

Here is the worry. The scientific outlook has taught us that some parts of our subjective experience are products of our biological makeup and have no objective counterpart in the world. The qualitative difference between red and green, the tastiness of fruit and foulness of carrion, the scariness of heights and prettiness of flowers are design features of our common nervous system, and if our species had evolved in a different ecosystem or if we were missing a few genes, our reactions could go the other way. Now, if the distinction between right and wrong is also a product of brain wiring, why should we believe it is any more real than the distinction between red and green? And if it is just a collective hallucination, how could we argue that evils like genocide and slavery are wrong for everyone, rather than just distasteful to us?

Putting God in charge of morality is one way to solve the problem, of course, but Plato made short work of it 2,400 years ago. Does God have a good reason for designating certain acts as moral and others as immoral? If not â€” if his dictates are divine whims â€” why should we take them seriously? Suppose that God commanded us to torture a child. Would that make it all right, or would some other standard give us reasons to resist? And if, on the other hand, God was forced by moral reasons to issue some dictates and not others â€” if a command to torture a child was never an option â€” then why not appeal to those reasons directly?

This throws us back to wondering where those reasons could come from, if they are more than just figments of our brains. They certainly arenâ€™t in the physical world like wavelength or mass. The only other option is that moral truths exist in some abstract Platonic realm, there for us to discover, perhaps in the same way that mathematical truths (according to most mathematicians) are there for us to discover. On this analogy, we are born with a rudimentary concept of number, but as soon as we build on it with formal mathematical reasoning, the nature of mathematical reality forces us to discover some truths and not others. (No one who understands the concept of two, the concept of four and the concept of addition can come to any conclusion but that 2 + 2 = 4.) Perhaps we are born with a rudimentary moral sense, and as soon as we build on it with moral reasoning, the nature of moral reality forces us to some conclusions but not others.

Moral realism, as this idea is called, is too rich for many philosophersâ€™ blood. Yet a diluted version of the idea â€” if not a list of cosmically inscribed Thou-Shalts, then at least a few If-Thens â€” is not crazy. Two features of reality point any rational, self-preserving social agent in a moral direction. And they could provide a benchmark for determining when the judgments of our moral sense are aligned with morality itself.

One is the prevalence of nonzero-sum games. In many arenas of life, two parties are objectively better off if they both act in a nonselfish way than if each of them acts selfishly. You and I are both better off if we share our surpluses, rescue each otherâ€™s children in danger and refrain from shooting at each other, compared with hoarding our surpluses while they rot, letting the otherâ€™s child drown while we file our nails or feuding like the Hatfields and McCoys. Granted, I might be a bit better off if I acted selfishly at your expense and you played the sucker, but the same is true for you with me, so if each of us tried for these advantages, weâ€™d both end up worse off. Any neutral observer, and you and I if we could talk it over rationally, would have to conclude that the state we should aim for is the one in which we both are unselfish. These spreadsheet projections are not quirks of brain wiring, nor are they dictated by a supernatural power; they are in the nature of things.

The other external support for morality is a feature of rationality itself: that it cannot depend on the egocentric vantage point of the reasoner. If I appeal to you to do anything that affects me â€” to get off my foot, or tell me the time or not run me over with your car â€” then I canâ€™t do it in a way that privileges my interests over yours (say, retaining my right to run you over with my car) if I want you to take me seriously. Unless I am Galactic Overlord, I have to state my case in a way that would force me to treat you in kind. I canâ€™t act as if my interests are special just because Iâ€™m me and youâ€™re not, any more than I can persuade you that the spot I am standing on is a special place in the universe just because I happen to be standing on it.

Not coincidentally, the core of this idea â€” the interchangeability of perspectives â€” keeps reappearing in historyâ€™s best-thought-through moral philosophies, including the Golden Rule (itself discovered many times); Spinozaâ€™s Viewpoint of Eternity; the Social Contract of Hobbes, Rousseau and Locke; Kantâ€™s Categorical Imperative; and Rawlsâ€™s Veil of Ignorance. It also underlies Peter Singerâ€™s theory of the Expanding Circle â€” the optimistic proposal that our moral sense, though shaped by evolution to overvalue self, kin and clan, can propel us on a path of moral progress, as our reasoning forces us to generalize it to larger and larger circles of sentient beings.

Doing Better by Knowing Ourselves

Morality, then, is still something larger than our inherited moral sense, and the new science of the moral sense does not make moral reasoning and conviction obsolete. At the same time, its implications for our moral universe are profound.

At the very least, the science tells us that even when our adversariesâ€™ agenda is most baffling, they may not be amoral psychopaths but in the throes of a moral mind-set that appears to them to be every bit as mandatory and universal as ours does to us. Of course, some adversaries really are psychopaths, and others are so poisoned by a punitive moralization that they are beyond the pale of reason. (The actor Will Smith had many historians on his side when he recently speculated to the press that Hitler thought he was acting morally.) But in any conflict in which a meeting of the minds is not completely hopeless, a recognition that the other guy is acting from moral rather than venal reasons can be a first patch of common ground. One side can acknowledge the otherâ€™s concern for community or stability or fairness or dignity, even while arguing that some other value should trump it in that instance. With affirmative action, for example, the opponents can be seen as arguing from a sense of fairness, not racism, and the defenders can be seen as acting from a concern with community, not bureaucratic power. Liberals can ratify conservativesâ€™ concern with families while noting that gay marriage is perfectly consistent with that concern.

The science of the moral sense also alerts us to ways in which our psychological makeup can get in the way of our arriving at the most defensible moral conclusions. The moral sense, we are learning, is as vulnerable to illusions as the other senses. It is apt to confuse morality per se with purity, status and conformity. It tends to reframe practical problems as moral crusades and thus see their solution in punitive aggression. It imposes taboos that make certain ideas indiscussible. And it has the nasty habit of always putting the self on the side of the angels.

Though wise people have long reflected on how we can be blinded by our own sanctimony, our public discourse still fails to discount it appropriately. In the worst cases, the thoughtlessness of our brute intuitions can be celebrated as a virtue. In his influential essay â€œThe Wisdom of Repugnance,â€ Leon Kass, former chair of the Presidentâ€™s Council on Bioethics, argued that we should disregard reason when it comes to cloning and other biomedical technologies and go with our gut: â€œWe are repelled by the prospect of cloning human beings . . . because we intuit and feel, immediately and without argument, the violation of things that we rightfully hold dear. . . . In this age in which everything is held to be permissible so long as it is freely done . . . repugnance may be the only voice left that speaks up to defend the central core of our humanity. Shallow are the souls that have forgotten how to shudder.â€

There are, of course, good reasons to regulate human cloning, but the shudder test is not one of them. People have shuddered at all kinds of morally irrelevant violations of purity in their culture: touching an untouchable, drinking from the same water fountain as a Negro, allowing Jewish blood to mix with Aryan blood, tolerating sodomy between consenting men. And if our ancestorsâ€™ repugnance had carried the day, we never would have had autopsies, vaccinations, blood transfusions, artificial insemination, organ transplants and in vitro fertilization, all of which were denounced as immoral when they were new.

There are many other issues for which we are too quick to hit the moralization button and look for villains rather than bug fixes. What should we do when a hospital patient is killed by a nurse who administers the wrong drug in a patientâ€™s intravenous line? Should we make it easier to sue the hospital for damages? Or should we redesign the IV fittings so that itâ€™s physically impossible to connect the wrong bottle to the line?

And nowhere is moralization more of a hazard than in our greatest global challenge. The threat of human-induced climate change has become the occasion for a moralistic revival meeting. In many discussions, the cause of climate change is overindulgence (too many S.U.V.â€™s) and defilement (sullying the atmosphere), and the solution is temperance (conservation) and expiation (buying carbon offset coupons). Yet the experts agree that these numbers donâ€™t add up: even if every last American became conscientious about his or her carbon emissions, the effects on climate change would be trifling, if for no other reason than that two billion Indians and Chinese are unlikely to copy our born-again abstemiousness. Though voluntary conservation may be one wedge in an effective carbon-reduction pie, the other wedges will have to be morally boring, like a carbon tax and new energy technologies, or even taboo, like nuclear power and deliberate manipulation of the ocean and atmosphere. Our habit of moralizing problems, merging them with intuitions of purity and contamination, and resting content when we feel the right feelings, can get in the way of doing the right thing.

Far from debunking morality, then, the science of the moral sense can advance it, by allowing us to see through the illusions that evolution and culture have saddled us with and to focus on goals we can share and defend. As Anton Chekhov wrote, â€œMan will become better when you show him what he is like.â€

Steven Pinker is the Johnstone Family Professor of Psychology at Harvard University and the author of â€œThe Language Instinctâ€ and â€œThe Stuff of
Thought: Language as a Window Into Human Nature.â€


Copyright 2008 The New York Times Company
Privacy Policy Search Corrections RSS First Look Help Contact Us Work for Us Site Map
 

























